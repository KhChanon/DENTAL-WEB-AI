{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLWMreRfX3KP",
        "outputId": "257ff626-3f26-4f56-ed33-98f6e58620af"
      },
      "outputs": [],
      "source": [
        "!pip install nlpaug\n",
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdO6W-oGxi2c"
      },
      "outputs": [],
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "from googletrans import Translator\n",
        "import string\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from nlpaug.util import Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAaaphlReTJ7"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    cleaned_text = text.translate(translator)\n",
        "    return cleaned_text\n",
        "\n",
        "def paraphrase_thai(text):\n",
        "    # Translate to English\n",
        "    translator = Translator()\n",
        "    english_text = translator.translate(text, dest='en')\n",
        "    en_text = remove_punctuation(english_text.text)\n",
        "\n",
        "    # Paraphrase in English (you can use other libraries or models for this step)\n",
        "    paraphrased_englishs = paraphrase_function(en_text)\n",
        "\n",
        "    # Translate back to Thai\n",
        "    th_texts =[]\n",
        "\n",
        "    for paraphrased_english in paraphrased_englishs:\n",
        "      paraphrased_thai = translator.translate(paraphrased_english, dest='th')\n",
        "      th_text = remove_punctuation(paraphrased_thai.text)\n",
        "      th_texts.append(th_text)\n",
        "\n",
        "    return th_texts\n",
        "\n",
        "def paraphrase_function(\n",
        "    question,\n",
        "    num_beams=5,\n",
        "    num_beam_groups=5,\n",
        "    num_return_sequences=5,\n",
        "    repetition_penalty=10.0,\n",
        "    diversity_penalty=3.0,\n",
        "    no_repeat_ngram_size=2,\n",
        "    max_length=128\n",
        "):\n",
        "    input_ids = tokenizer(\n",
        "        f'paraphrase: {question}',\n",
        "        return_tensors=\"pt\", padding=\"longest\",\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    ).input_ids.to('cuda:0')\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids, repetition_penalty=repetition_penalty,\n",
        "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
        "        max_length=max_length, diversity_penalty=diversity_penalty\n",
        "    )\n",
        "\n",
        "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return res\n",
        "\n",
        "def random_insert(text, aug_char_p=0.05):\n",
        "    thai_letters = [chr(code) for code in range(0xE01, 0xE3A)]  # U+0E01 to U+0E39\n",
        "    aug_insert = nac.RandomCharAug(action='insert', candidates=thai_letters, aug_char_p=aug_char_p)\n",
        "    insert_augmented = aug_insert.augment(text)\n",
        "    insert_augment_noweirdspace = insert_augmented[0].replace('\\xa0', '')\n",
        "    return insert_augment_noweirdspace.replace(' ', '')\n",
        "\n",
        "def random_deletion(text, aug_char_p=0.05):\n",
        "    aug_delete = nac.RandomCharAug(action='delete', aug_char_p=aug_char_p)\n",
        "    delete_augmented = aug_delete.augment(text)\n",
        "    delete_augment_noweirdspace = delete_augmented[0].replace('\\xa0', '')\n",
        "    return delete_augment_noweirdspace.replace(' ', '')\n",
        "\n",
        "def random_swap(text, aug_char_p=0.05):\n",
        "    aug_swap = nac.RandomCharAug(action='swap', aug_char_p=aug_char_p)\n",
        "    swap_augmented = aug_swap.augment(text)\n",
        "    swap_augment_noweirdspace = swap_augmented[0].replace('\\xa0', ' ')\n",
        "    return swap_augment_noweirdspace.replace(' ', '')\n",
        "\n",
        "def back_translation(text, destination_language='en'):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(text, dest=destination_language)\n",
        "    return translation.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMRRk55t5Bac",
        "outputId": "f921d246-ff57-4b74-e44e-86bc32694126"
      },
      "outputs": [],
      "source": [
        "# Sample Thai question\n",
        "thai_question = \"วิทยาศาสตร์ควอนตัมคืออะไร\"\n",
        "\n",
        "# Call the functions and store the augmented texts\n",
        "insert_augmented = random_insert(thai_question)\n",
        "delete_augmented = random_deletion(thai_question)\n",
        "swap_augmented = random_swap(thai_question)\n",
        "back_translation_result = back_translation(thai_question)\n",
        "paraphrased_texts = paraphrase_thai(thai_question)\n",
        "\n",
        "# Display the augmented texts\n",
        "print(f\"Random Insertion: {insert_augmented}\")\n",
        "print(f\"Random Deletion: {delete_augmented}\")\n",
        "print(f\"Random Swap: {swap_augmented}\")\n",
        "print(f\"Back Translation: {back_translation_result}\")\n",
        "for paraphrased_text in paraphrased_texts:\n",
        "  print(f\"Paraphrased text: {paraphrased_text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_CmlHab63zV",
        "outputId": "7b1ab1f0-9efa-45a3-882c-33ee8ed94d7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "Question_Counter = 0\n",
        "augment_counter = 0\n",
        "# Read the CSV file\n",
        "input_csv_path = 'qalist.csv'\n",
        "output_csv_path = 'augmented_output_file.csv'\n",
        "\n",
        "df = pd.read_csv(input_csv_path)\n",
        "\n",
        "# Create a new DataFrame to store augmented data\n",
        "augmented_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "# Augment each row in the original DataFrame and add as new rows in the augmented DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    Question_Counter+=1\n",
        "    print(f\"Quesiton:{Question_Counter}\")\n",
        "    thai_question = row['question']\n",
        "    index_class = row['class']\n",
        "\n",
        "    aug_questions=[]\n",
        "\n",
        "    aug_questions.append(random_insert(thai_question))\n",
        "    aug_questions.append(random_insert(thai_question))\n",
        "    aug_questions.append(random_deletion(thai_question))\n",
        "    aug_questions.append(random_deletion(thai_question))\n",
        "    aug_questions.append(random_swap(thai_question))\n",
        "    aug_questions.append(random_swap(thai_question))\n",
        "    aug_questions.extend(paraphrase_thai(thai_question))\n",
        "\n",
        "    # Append augmented data as new rows in the augmented DataFrame\n",
        "    for aug_question in aug_questions:\n",
        "      augment_counter+=1\n",
        "      print(f\"Augment:{augment_counter}\")\n",
        "      aug_df = pd.DataFrame({\n",
        "        'question': aug_questions,\n",
        "        'class': index_class\n",
        "      })\n",
        "\n",
        "      # Concatenate the augmented DataFrame with the original DataFrame\n",
        "      augmented_df = pd.concat([augmented_df, aug_df], ignore_index=True)\n",
        "\n",
        "# Concatenate the original DataFrame with the augmented DataFrame\n",
        "result_df = pd.concat([df, augmented_df], ignore_index=True)\n",
        "\n",
        "# Save the result DataFrame to a new CSV file\n",
        "result_df.to_csv(output_csv_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
